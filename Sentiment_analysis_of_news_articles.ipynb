{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import codecs\n",
    "from nltk.corpus import stopwords\n",
    "import preprocessing_tools as pr\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import cross_val_score,KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('train.json',encoding = 'UTF-8')\n",
    "# Заменяем позитивный маркер на 1, негативный на -1, нейтральный на 0\n",
    "train['sentiment'] = train['sentiment'].replace(['positive' ,'neutral','negative'],[1,0,-1])\n",
    "# задаем целевую переменную\n",
    "target = train['sentiment']\n",
    "test_data = pd.read_json('test.json',encoding = 'UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8263\n",
      "2795\n",
      "1434\n",
      "4034\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(train[train.sentiment == 1]))\n",
    "print(len(train[train.sentiment == -1]))\n",
    "print(len(train[train.sentiment == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1945</td>\n",
       "      <td>-1</td>\n",
       "      <td>Досудебное расследование по факту покупки ЕНПФ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1957</td>\n",
       "      <td>-1</td>\n",
       "      <td>Медики рассказали о состоянии пострадавшего му...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1969</td>\n",
       "      <td>-1</td>\n",
       "      <td>Прошел почти год, как железнодорожным оператор...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1973</td>\n",
       "      <td>-1</td>\n",
       "      <td>По итогам 12 месяцев 2016 года на территории р...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1975</td>\n",
       "      <td>-1</td>\n",
       "      <td>Астана. 21 ноября. Kazakhstan Today - Агентств...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  sentiment                                               text\n",
       "0  1945         -1  Досудебное расследование по факту покупки ЕНПФ...\n",
       "1  1957         -1  Медики рассказали о состоянии пострадавшего му...\n",
       "2  1969         -1  Прошел почти год, как железнодорожным оператор...\n",
       "3  1973         -1  По итогам 12 месяцев 2016 года на территории р...\n",
       "4  1975         -1  Астана. 21 ноября. Kazakhstan Today - Агентств..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка (очищение и лемматизация)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "train['text'] = train['text'].apply(pr.clean_text)\n",
    "test_data['text'] = test_data['text'].apply(pr.clean_text)\n",
    "train['lemmas'] = train['text'].apply(pr.lemmatization)\n",
    "test_data['lemmas'] = test_data['text'].apply(pr.lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1945</td>\n",
       "      <td>-1</td>\n",
       "      <td>досудебное расследование по факту покупки енпф...</td>\n",
       "      <td>[досудебный, расследование, факт, покупка, енп...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1957</td>\n",
       "      <td>-1</td>\n",
       "      <td>медики рассказали о состоянии пострадавшего му...</td>\n",
       "      <td>[медик, состояние, пострадавший, мужчина, сове...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1969</td>\n",
       "      <td>-1</td>\n",
       "      <td>прошел почти год как железнодорожным оператора...</td>\n",
       "      <td>[железнодорожный, оператор, запретить, эксплуа...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1973</td>\n",
       "      <td>-1</td>\n",
       "      <td>по итогам  месяцев  года на территории республ...</td>\n",
       "      <td>[итог, месяц, территория, республика, выпустит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1975</td>\n",
       "      <td>-1</td>\n",
       "      <td>астана  ноября kazakhstan today  агентство рк ...</td>\n",
       "      <td>[астан, kazakhstan, today, агентство, рк, госу...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  sentiment                                               text  \\\n",
       "0  1945         -1  досудебное расследование по факту покупки енпф...   \n",
       "1  1957         -1  медики рассказали о состоянии пострадавшего му...   \n",
       "2  1969         -1  прошел почти год как железнодорожным оператора...   \n",
       "3  1973         -1  по итогам  месяцев  года на территории республ...   \n",
       "4  1975         -1  астана  ноября kazakhstan today  агентство рк ...   \n",
       "\n",
       "                                              lemmas  \n",
       "0  [досудебный, расследование, факт, покупка, енп...  \n",
       "1  [медик, состояние, пострадавший, мужчина, сове...  \n",
       "2  [железнодорожный, оператор, запретить, эксплуа...  \n",
       "3  [итог, месяц, территория, республика, выпустит...  \n",
       "4  [астан, kazakhstan, today, агентство, рк, госу...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['lemmas'] = train['lemmas'].apply(str)\n",
    "test_data['lemmas'] = test_data['text'].apply(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Различные модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "text_clf = Pipeline([('vectorizer', TfidfVectorizer()),\n",
    "                     ('clf', LinearSVC())])\n",
    "\n",
    "tuned_parameters = {\n",
    "    'vectorizer__ngram_range': [ (1, 2), (2, 2)],\n",
    "    'vectorizer__norm': ('l1', 'l2'), \n",
    "    'vectorizer__sublinear_tf': (True, False),\n",
    "    'clf__loss': ('hinge','squared_hinge'), \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'vectorizer', 'clf', 'vectorizer__analyzer', 'vectorizer__binary', 'vectorizer__decode_error', 'vectorizer__dtype', 'vectorizer__encoding', 'vectorizer__input', 'vectorizer__lowercase', 'vectorizer__max_df', 'vectorizer__max_features', 'vectorizer__min_df', 'vectorizer__ngram_range', 'vectorizer__norm', 'vectorizer__preprocessor', 'vectorizer__smooth_idf', 'vectorizer__stop_words', 'vectorizer__strip_accents', 'vectorizer__sublinear_tf', 'vectorizer__token_pattern', 'vectorizer__tokenizer', 'vectorizer__use_idf', 'vectorizer__vocabulary', 'clf__C', 'clf__class_weight', 'clf__dual', 'clf__fit_intercept', 'clf__intercept_scaling', 'clf__loss', 'clf__max_iter', 'clf__multi_class', 'clf__penalty', 'clf__random_state', 'clf__tol', 'clf__verbose'])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train['lemmas'], target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1_macro\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\MyPrograms\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\MyPrograms\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'clf__loss': 'hinge', 'vectorizer__ngram_range': (1, 2), 'vectorizer__norm': 'l2', 'vectorizer__sublinear_tf': True}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.472 (+/-0.074) for {'clf__loss': 'hinge', 'vectorizer__ngram_range': (1, 2), 'vectorizer__norm': 'l1', 'vectorizer__sublinear_tf': True}\n",
      "0.468 (+/-0.060) for {'clf__loss': 'hinge', 'vectorizer__ngram_range': (1, 2), 'vectorizer__norm': 'l1', 'vectorizer__sublinear_tf': False}\n",
      "0.698 (+/-0.055) for {'clf__loss': 'hinge', 'vectorizer__ngram_range': (1, 2), 'vectorizer__norm': 'l2', 'vectorizer__sublinear_tf': True}\n",
      "0.693 (+/-0.048) for {'clf__loss': 'hinge', 'vectorizer__ngram_range': (1, 2), 'vectorizer__norm': 'l2', 'vectorizer__sublinear_tf': False}\n",
      "0.436 (+/-0.078) for {'clf__loss': 'hinge', 'vectorizer__ngram_range': (2, 2), 'vectorizer__norm': 'l1', 'vectorizer__sublinear_tf': True}\n",
      "0.441 (+/-0.070) for {'clf__loss': 'hinge', 'vectorizer__ngram_range': (2, 2), 'vectorizer__norm': 'l1', 'vectorizer__sublinear_tf': False}\n",
      "0.679 (+/-0.051) for {'clf__loss': 'hinge', 'vectorizer__ngram_range': (2, 2), 'vectorizer__norm': 'l2', 'vectorizer__sublinear_tf': True}\n",
      "0.674 (+/-0.050) for {'clf__loss': 'hinge', 'vectorizer__ngram_range': (2, 2), 'vectorizer__norm': 'l2', 'vectorizer__sublinear_tf': False}\n",
      "0.238 (+/-0.016) for {'clf__loss': 'squared_hinge', 'vectorizer__ngram_range': (1, 2), 'vectorizer__norm': 'l1', 'vectorizer__sublinear_tf': True}\n",
      "0.255 (+/-0.023) for {'clf__loss': 'squared_hinge', 'vectorizer__ngram_range': (1, 2), 'vectorizer__norm': 'l1', 'vectorizer__sublinear_tf': False}\n",
      "0.693 (+/-0.051) for {'clf__loss': 'squared_hinge', 'vectorizer__ngram_range': (1, 2), 'vectorizer__norm': 'l2', 'vectorizer__sublinear_tf': True}\n",
      "0.691 (+/-0.052) for {'clf__loss': 'squared_hinge', 'vectorizer__ngram_range': (1, 2), 'vectorizer__norm': 'l2', 'vectorizer__sublinear_tf': False}\n",
      "0.237 (+/-0.016) for {'clf__loss': 'squared_hinge', 'vectorizer__ngram_range': (2, 2), 'vectorizer__norm': 'l1', 'vectorizer__sublinear_tf': True}\n",
      "0.243 (+/-0.024) for {'clf__loss': 'squared_hinge', 'vectorizer__ngram_range': (2, 2), 'vectorizer__norm': 'l1', 'vectorizer__sublinear_tf': False}\n",
      "0.667 (+/-0.049) for {'clf__loss': 'squared_hinge', 'vectorizer__ngram_range': (2, 2), 'vectorizer__norm': 'l2', 'vectorizer__sublinear_tf': True}\n",
      "0.666 (+/-0.047) for {'clf__loss': 'squared_hinge', 'vectorizer__ngram_range': (2, 2), 'vectorizer__norm': 'l2', 'vectorizer__sublinear_tf': False}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1     0.7803    0.6398    0.7031       483\n",
      "           0     0.7299    0.7819    0.7550      1334\n",
      "           1     0.7262    0.7198    0.7230       910\n",
      "\n",
      "   micro avg     0.7360    0.7360    0.7360      2727\n",
      "   macro avg     0.7454    0.7138    0.7270      2727\n",
      "weighted avg     0.7376    0.7360    0.7351      2727\n",
      "\n",
      "\n",
      "Wall time: 59min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "score = 'f1_macro'\n",
    "print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "print()\n",
    "np.errstate(divide='ignore')\n",
    "cv = StratifiedShuffleSplit(n_splits = 10, test_size = 0.33, random_state = 0)\n",
    "cv_kfold = StratifiedKFold(n_splits=10, random_state=0)\n",
    "clf = GridSearchCV(text_clf, tuned_parameters, cv=10, scoring=score)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "for mean, std, params in zip(clf.cv_results_['mean_test_score'], \n",
    "                             clf.cv_results_['std_test_score'], \n",
    "                             clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "print(classification_report(y_val, clf.predict(X_val), digits=4))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\MyPrograms\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "C:\\MyPrograms\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.45: 0.7288256227758008\n",
      "Accuracy for C=0.5: 0.7295373665480427\n",
      "Accuracy for C=0.55: 0.7327402135231317\n",
      "Accuracy for C=1: 0.7355871886120996\n",
      "Accuracy for C=1.05: 0.7362989323843416\n",
      "Accuracy for C=1.1: 0.7366548042704626\n",
      "Accuracy for C=1.15: 0.7380782918149467\n",
      "Final Accuracy: 0.7355871886120996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1     0.7531    0.6305    0.6864       479\n",
      "           0     0.7267    0.7801    0.7525      1360\n",
      "           1     0.7418    0.7250    0.7333       971\n",
      "\n",
      "   micro avg     0.7356    0.7356    0.7356      2810\n",
      "   macro avg     0.7406    0.7119    0.7241      2810\n",
      "weighted avg     0.7364    0.7356    0.7346      2810\n",
      "\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, min_df=6, norm='l2', ngram_range=(1, 2),encoding='cp1251', \n",
    "                                   stop_words=stopwords.words('russian'))\n",
    "\n",
    "tfidf_vectorizer.fit(train['lemmas'])\n",
    "X = tfidf_vectorizer.transform(train['lemmas'])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.66\n",
    ")\n",
    "\n",
    "for c in [ 0.45, 0.5, 0.55, 1, 1.05, 1.1,1.15]:\n",
    "    \n",
    "    svm = LinearSVC(C=c, multi_class = 'ovr', loss = 'hinge')\n",
    "    svm.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val))))\n",
    "    \n",
    "    \n",
    "final_svm_tfidf = LinearSVC(C=1, multi_class = 'ovr', loss = 'hinge')\n",
    "final_svm_tfidf.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(y_val, final_svm_tfidf.predict(X_val)))\n",
    "print (classification_report(y_val,final_svm_tfidf.predict(X_val), digits = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "text_clf = Pipeline([('vectorizer', TfidfVectorizer()),\n",
    "                     ('clf', MultinomialNB())])\n",
    "\n",
    "tuned_parameters = {\n",
    "    'vectorizer__ngram_range': [ (1, 2), (2, 2)],\n",
    "    #'vectorizer__sublinear_tf': (True, False),\n",
    "    #'vectorizer__norm': ('l1', 'l2'),\n",
    "    'vectorizer__min_df': (4,5,6),\n",
    "    'clf__alpha': [1, 1e-1, 1e-2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train['lemmas'], target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1_macro\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'clf__alpha': 0.01, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2)}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.518 (+/-0.034) for {'clf__alpha': 1, 'vectorizer__min_df': 4, 'vectorizer__ngram_range': (1, 2)}\n",
      "0.610 (+/-0.043) for {'clf__alpha': 1, 'vectorizer__min_df': 4, 'vectorizer__ngram_range': (2, 2)}\n",
      "0.546 (+/-0.036) for {'clf__alpha': 1, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2)}\n",
      "0.616 (+/-0.040) for {'clf__alpha': 1, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 2)}\n",
      "0.561 (+/-0.039) for {'clf__alpha': 1, 'vectorizer__min_df': 6, 'vectorizer__ngram_range': (1, 2)}\n",
      "0.621 (+/-0.040) for {'clf__alpha': 1, 'vectorizer__min_df': 6, 'vectorizer__ngram_range': (2, 2)}\n",
      "0.677 (+/-0.046) for {'clf__alpha': 0.1, 'vectorizer__min_df': 4, 'vectorizer__ngram_range': (1, 2)}\n",
      "0.675 (+/-0.046) for {'clf__alpha': 0.1, 'vectorizer__min_df': 4, 'vectorizer__ngram_range': (2, 2)}\n",
      "0.675 (+/-0.044) for {'clf__alpha': 0.1, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2)}\n",
      "0.671 (+/-0.047) for {'clf__alpha': 0.1, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 2)}\n",
      "0.675 (+/-0.043) for {'clf__alpha': 0.1, 'vectorizer__min_df': 6, 'vectorizer__ngram_range': (1, 2)}\n",
      "0.670 (+/-0.046) for {'clf__alpha': 0.1, 'vectorizer__min_df': 6, 'vectorizer__ngram_range': (2, 2)}\n",
      "0.685 (+/-0.048) for {'clf__alpha': 0.01, 'vectorizer__min_df': 4, 'vectorizer__ngram_range': (1, 2)}\n",
      "0.678 (+/-0.049) for {'clf__alpha': 0.01, 'vectorizer__min_df': 4, 'vectorizer__ngram_range': (2, 2)}\n",
      "0.687 (+/-0.044) for {'clf__alpha': 0.01, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 2)}\n",
      "0.672 (+/-0.046) for {'clf__alpha': 0.01, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (2, 2)}\n",
      "0.681 (+/-0.039) for {'clf__alpha': 0.01, 'vectorizer__min_df': 6, 'vectorizer__ngram_range': (1, 2)}\n",
      "0.672 (+/-0.050) for {'clf__alpha': 0.01, 'vectorizer__min_df': 6, 'vectorizer__ngram_range': (2, 2)}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1     0.7290    0.7019    0.7152       483\n",
      "           0     0.7436    0.7174    0.7303      1334\n",
      "           1     0.6903    0.7396    0.7141       910\n",
      "\n",
      "   micro avg     0.7220    0.7220    0.7220      2727\n",
      "   macro avg     0.7210    0.7196    0.7198      2727\n",
      "weighted avg     0.7232    0.7220    0.7222      2727\n",
      "\n",
      "\n",
      "Wall time: 29min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "score = 'f1_macro'\n",
    "print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "print()\n",
    "np.errstate(divide='ignore')\n",
    "clf = GridSearchCV(text_clf, tuned_parameters, cv=10, scoring=score)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "for mean, std, params in zip(clf.cv_results_['mean_test_score'], \n",
    "                             clf.cv_results_['std_test_score'], \n",
    "                             clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "print(classification_report(y_val, clf.predict(X_val), digits=4))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\MyPrograms\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.0001: 0.7128113879003559\n",
      "Accuracy for C=0.001: 0.7160142348754448\n",
      "Accuracy for C=0.01: 0.7120996441281139\n",
      "Accuracy for C=0.05: 0.706049822064057\n",
      "Accuracy for C=0.25: 0.7067615658362989\n",
      "Accuracy for C=0.45: 0.695373665480427\n",
      "Accuracy for C=0.5: 0.695017793594306\n",
      "Accuracy for C=0.55: 0.69288256227758\n",
      "Accuracy for C=1: 0.6633451957295373\n",
      "Accuracy for C=1.05: 0.6587188612099644\n",
      "Accuracy for C=1.1: 0.6551601423487544\n",
      "Final Accuracy: 0.7160142348754448\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1    0.73171   0.60852   0.66445       493\n",
      "           0    0.71725   0.72530   0.72125      1336\n",
      "           1    0.70829   0.75739   0.73202       981\n",
      "\n",
      "   micro avg    0.71601   0.71601   0.71601      2810\n",
      "   macro avg    0.71908   0.69707   0.70591      2810\n",
      "weighted avg    0.71666   0.71601   0.71505      2810\n",
      "\n",
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, min_df=6, norm='l2', ngram_range=(1, 2),encoding='cp1251', \n",
    "                                   stop_words=stopwords.words('russian'))\n",
    "\n",
    "tfidf_vectorizer.fit(train['lemmas'])\n",
    "X = tfidf_vectorizer.transform(train['lemmas'])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.66\n",
    ")\n",
    "\n",
    "for alpha in [0.0001, 0.001, 0.01, 0.05, 0.25, 0.45, 0.5, 0.55, 1, 1.05, 1.1]:\n",
    "    \n",
    "    NB = OneVsRestClassifier(MultinomialNB(alpha = alpha, fit_prior=True, class_prior=None))\n",
    "    NB.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (alpha, accuracy_score(y_val, NB.predict(X_val))))\n",
    "    \n",
    "    \n",
    "final_NB_tfidf = OneVsRestClassifier(MultinomialNB(alpha=0.001, fit_prior=True, class_prior=None))\n",
    "final_NB_tfidf.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(y_val, final_NB_tfidf.predict(X_val)))\n",
    "print (classification_report(y_val,final_NB_tfidf.predict(X_val), digits = 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
