{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import codecs\n",
    "from nltk.corpus import stopwords\n",
    "import preprocessing_tools as pr\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import cross_val_score,KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Два класса: positive, negative"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train = pd.read_json('train.json',encoding = 'UTF-8')\n",
    "# дропаем нейтральные отзывы\n",
    "train = train[train.sentiment != 'neutral']\n",
    "# Заменяем позитивный маркер на 1, негативный на -1\n",
    "train['sentiment'] = train['sentiment'].replace(['positive' ,'negative'],[1,-1])\n",
    "# задаем целевую переменную\n",
    "target = train['sentiment']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(len(train))\n",
    "print(len(train[train.sentiment == 1]))\n",
    "print(len(train[train.sentiment == -1]))\n",
    "#print(len(train[train.sentiment == 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Три класса: positive, neutral, negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('train.json',encoding = 'UTF-8')\n",
    "# Заменяем позитивный маркер на 1, негативный на -1, нейтральный на 0\n",
    "train['sentiment'] = train['sentiment'].replace(['positive' ,'neutral','negative'],[1,0,-1])\n",
    "# задаем целевую переменную\n",
    "target = train['sentiment']\n",
    "test_data = pd.read_json('test.json',encoding = 'UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8263\n",
      "2795\n",
      "1434\n",
      "4034\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(train[train.sentiment == 1]))\n",
    "print(len(train[train.sentiment == -1]))\n",
    "print(len(train[train.sentiment == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1945</td>\n",
       "      <td>-1</td>\n",
       "      <td>Досудебное расследование по факту покупки ЕНПФ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1957</td>\n",
       "      <td>-1</td>\n",
       "      <td>Медики рассказали о состоянии пострадавшего му...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1969</td>\n",
       "      <td>-1</td>\n",
       "      <td>Прошел почти год, как железнодорожным оператор...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1973</td>\n",
       "      <td>-1</td>\n",
       "      <td>По итогам 12 месяцев 2016 года на территории р...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1975</td>\n",
       "      <td>-1</td>\n",
       "      <td>Астана. 21 ноября. Kazakhstan Today - Агентств...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  sentiment                                               text\n",
       "0  1945         -1  Досудебное расследование по факту покупки ЕНПФ...\n",
       "1  1957         -1  Медики рассказали о состоянии пострадавшего му...\n",
       "2  1969         -1  Прошел почти год, как железнодорожным оператор...\n",
       "3  1973         -1  По итогам 12 месяцев 2016 года на территории р...\n",
       "4  1975         -1  Астана. 21 ноября. Kazakhstan Today - Агентств..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Очищаем текст и лемматизируем\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "train['text'] = train['text'].apply(pr.clean_text)\n",
    "test_data['text'] = test_data['text'].apply(pr.clean_text)\n",
    "train['lemmas'] = train['text'].apply(pr.lemmatization)\n",
    "test_data['lemmas'] = test_data['text'].apply(pr.lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1945</td>\n",
       "      <td>-1</td>\n",
       "      <td>досудебное расследование по факту покупки енпф...</td>\n",
       "      <td>[досудебный, расследование, факт, покупка, енп...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1957</td>\n",
       "      <td>-1</td>\n",
       "      <td>медики рассказали о состоянии пострадавшего му...</td>\n",
       "      <td>[медик, состояние, пострадавший, мужчина, сове...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1969</td>\n",
       "      <td>-1</td>\n",
       "      <td>прошел почти год как железнодорожным оператора...</td>\n",
       "      <td>[железнодорожный, оператор, запретить, эксплуа...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1973</td>\n",
       "      <td>-1</td>\n",
       "      <td>по итогам  месяцев  года на территории республ...</td>\n",
       "      <td>[итог, месяц, территория, республика, выпустит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1975</td>\n",
       "      <td>-1</td>\n",
       "      <td>астана  ноября kazakhstan today  агентство рк ...</td>\n",
       "      <td>[астан, kazakhstan, today, агентство, рк, госу...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  sentiment                                               text  \\\n",
       "0  1945         -1  досудебное расследование по факту покупки енпф...   \n",
       "1  1957         -1  медики рассказали о состоянии пострадавшего му...   \n",
       "2  1969         -1  прошел почти год как железнодорожным оператора...   \n",
       "3  1973         -1  по итогам  месяцев  года на территории республ...   \n",
       "4  1975         -1  астана  ноября kazakhstan today  агентство рк ...   \n",
       "\n",
       "                                              lemmas  \n",
       "0  [досудебный, расследование, факт, покупка, енп...  \n",
       "1  [медик, состояние, пострадавший, мужчина, сове...  \n",
       "2  [железнодорожный, оператор, запретить, эксплуа...  \n",
       "3  [итог, месяц, территория, республика, выпустит...  \n",
       "4  [астан, kazakhstan, today, агентство, рк, госу...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['lemmas'] = train['lemmas'].apply(str)\n",
    "test_data['lemmas'] = test_data['text'].apply(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "text_clf = Pipeline([('vectorizer', TfidfVectorizer()),\n",
    "                     ('clf', LinearSVC())])\n",
    "\n",
    "tuned_parameters = {\n",
    "    'vectorizer__ngram_range': [ (1, 2), (2, 2)],\n",
    "   # 'vectorizer__use_idf': (True, False),\n",
    "    'vectorizer__norm': ('l1', 'l2'), #можно убрать \n",
    "    #'vectorizer__stop_words': (stopwords.words('russian'), None), #можно спокойно убирать\n",
    "   #'vectorizer__min_df': [4, 5, 6], #можно убрать, чтобы отдельно затестить\n",
    "    'vectorizer__sublinear_tf': (True, False),\n",
    "    #'clf__C': [ 0.5, 0.55], \n",
    "    'clf__loss': ('hinge','squared_hinge'), # тоже можно убрать\n",
    "    #'clf__penalty': ('l1','l2')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'vectorizer', 'clf', 'vectorizer__analyzer', 'vectorizer__binary', 'vectorizer__decode_error', 'vectorizer__dtype', 'vectorizer__encoding', 'vectorizer__input', 'vectorizer__lowercase', 'vectorizer__max_df', 'vectorizer__max_features', 'vectorizer__min_df', 'vectorizer__ngram_range', 'vectorizer__norm', 'vectorizer__preprocessor', 'vectorizer__smooth_idf', 'vectorizer__stop_words', 'vectorizer__strip_accents', 'vectorizer__sublinear_tf', 'vectorizer__token_pattern', 'vectorizer__tokenizer', 'vectorizer__use_idf', 'vectorizer__vocabulary', 'clf__C', 'clf__class_weight', 'clf__dual', 'clf__fit_intercept', 'clf__intercept_scaling', 'clf__loss', 'clf__max_iter', 'clf__multi_class', 'clf__penalty', 'clf__random_state', 'clf__tol', 'clf__verbose'])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train['lemmas'], target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1_macro\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\MyPrograms\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\MyPrograms\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'clf__loss': 'hinge', 'vectorizer__ngram_range': (1, 2), 'vectorizer__norm': 'l2', 'vectorizer__sublinear_tf': True}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.472 (+/-0.074) for {'clf__loss': 'hinge', 'vectorizer__ngram_range': (1, 2), 'vectorizer__norm': 'l1', 'vectorizer__sublinear_tf': True}\n",
      "0.467 (+/-0.061) for {'clf__loss': 'hinge', 'vectorizer__ngram_range': (1, 2), 'vectorizer__norm': 'l1', 'vectorizer__sublinear_tf': False}\n",
      "0.698 (+/-0.055) for {'clf__loss': 'hinge', 'vectorizer__ngram_range': (1, 2), 'vectorizer__norm': 'l2', 'vectorizer__sublinear_tf': True}\n",
      "0.693 (+/-0.048) for {'clf__loss': 'hinge', 'vectorizer__ngram_range': (1, 2), 'vectorizer__norm': 'l2', 'vectorizer__sublinear_tf': False}\n",
      "0.436 (+/-0.077) for {'clf__loss': 'hinge', 'vectorizer__ngram_range': (2, 2), 'vectorizer__norm': 'l1', 'vectorizer__sublinear_tf': True}\n",
      "0.440 (+/-0.070) for {'clf__loss': 'hinge', 'vectorizer__ngram_range': (2, 2), 'vectorizer__norm': 'l1', 'vectorizer__sublinear_tf': False}\n",
      "0.679 (+/-0.051) for {'clf__loss': 'hinge', 'vectorizer__ngram_range': (2, 2), 'vectorizer__norm': 'l2', 'vectorizer__sublinear_tf': True}\n",
      "0.674 (+/-0.050) for {'clf__loss': 'hinge', 'vectorizer__ngram_range': (2, 2), 'vectorizer__norm': 'l2', 'vectorizer__sublinear_tf': False}\n",
      "0.238 (+/-0.016) for {'clf__loss': 'squared_hinge', 'vectorizer__ngram_range': (1, 2), 'vectorizer__norm': 'l1', 'vectorizer__sublinear_tf': True}\n",
      "0.255 (+/-0.023) for {'clf__loss': 'squared_hinge', 'vectorizer__ngram_range': (1, 2), 'vectorizer__norm': 'l1', 'vectorizer__sublinear_tf': False}\n",
      "0.693 (+/-0.051) for {'clf__loss': 'squared_hinge', 'vectorizer__ngram_range': (1, 2), 'vectorizer__norm': 'l2', 'vectorizer__sublinear_tf': True}\n",
      "0.691 (+/-0.052) for {'clf__loss': 'squared_hinge', 'vectorizer__ngram_range': (1, 2), 'vectorizer__norm': 'l2', 'vectorizer__sublinear_tf': False}\n",
      "0.237 (+/-0.016) for {'clf__loss': 'squared_hinge', 'vectorizer__ngram_range': (2, 2), 'vectorizer__norm': 'l1', 'vectorizer__sublinear_tf': True}\n",
      "0.243 (+/-0.024) for {'clf__loss': 'squared_hinge', 'vectorizer__ngram_range': (2, 2), 'vectorizer__norm': 'l1', 'vectorizer__sublinear_tf': False}\n",
      "0.667 (+/-0.049) for {'clf__loss': 'squared_hinge', 'vectorizer__ngram_range': (2, 2), 'vectorizer__norm': 'l2', 'vectorizer__sublinear_tf': True}\n",
      "0.666 (+/-0.047) for {'clf__loss': 'squared_hinge', 'vectorizer__ngram_range': (2, 2), 'vectorizer__norm': 'l2', 'vectorizer__sublinear_tf': False}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1     0.7803    0.6398    0.7031       483\n",
      "           0     0.7299    0.7819    0.7550      1334\n",
      "           1     0.7262    0.7198    0.7230       910\n",
      "\n",
      "   micro avg     0.7360    0.7360    0.7360      2727\n",
      "   macro avg     0.7454    0.7138    0.7270      2727\n",
      "weighted avg     0.7376    0.7360    0.7351      2727\n",
      "\n",
      "\n",
      "Wall time: 58min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "score = 'f1_macro'\n",
    "print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "print()\n",
    "np.errstate(divide='ignore')\n",
    "cv = StratifiedShuffleSplit(n_splits = 10, test_size = 0.33, random_state = 0)\n",
    "cv_kfold = StratifiedKFold(n_splits=10, random_state=0)\n",
    "clf = GridSearchCV(text_clf, tuned_parameters, cv=10, scoring=score)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "for mean, std, params in zip(clf.cv_results_['mean_test_score'], \n",
    "                             clf.cv_results_['std_test_score'], \n",
    "                             clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "print(classification_report(y_val, clf.predict(X_val), digits=4))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\MyPrograms\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.5960854092526691\n",
      "Accuracy for C=0.05: 0.6405693950177936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\MyPrograms\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.25: 0.6903914590747331\n",
      "Accuracy for C=0.45: 0.7128113879003559\n",
      "Accuracy for C=0.5: 0.7142348754448399\n",
      "Accuracy for C=0.55: 0.7195729537366548\n",
      "Accuracy for C=1: 0.7263345195729537\n",
      "Final Accuracy: 0.7263345195729537\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1     0.7584    0.5996    0.6697       492\n",
      "           0     0.7197    0.7862    0.7515      1375\n",
      "           1     0.7236    0.7052    0.7143       943\n",
      "\n",
      "   micro avg     0.7263    0.7263    0.7263      2810\n",
      "   macro avg     0.7339    0.6970    0.7118      2810\n",
      "weighted avg     0.7278    0.7263    0.7247      2810\n",
      "\n",
      "Wall time: 43.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, min_df=6, norm='l2', ngram_range=(1, 2),encoding='cp1251', \n",
    "                                   stop_words=stopwords.words('russian'))\n",
    "\n",
    "tfidf_vectorizer.fit(train['lemmas'])\n",
    "X = tfidf_vectorizer.transform(train['lemmas'])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.66\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.45, 0.5, 0.55, 1]:\n",
    "    \n",
    "    svm = LinearSVC(C=c, multi_class = 'ovr', loss = 'hinge')\n",
    "    svm.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, svm.predict(X_val))))\n",
    "    \n",
    "    \n",
    "final_svm_tfidf = LinearSVC(C=1, multi_class = 'ovr', loss = 'hinge')\n",
    "final_svm_tfidf.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(y_val, final_svm_tfidf.predict(X_val)))\n",
    "print (classification_report(y_val,final_svm_tfidf.predict(X_val), digits = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "text_clf = Pipeline([('vectorizer', TfidfVectorizer()),\n",
    "                     ('clf', MultinomialNB())])\n",
    "\n",
    "tuned_parameters = {\n",
    "    'vectorizer__ngram_range': [ (1, 2), (2, 2)],\n",
    "    'vectorizer__sublinear_tf': (True, False),\n",
    "    'vectorizer__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': [1, 1e-1, 1e-2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train['lemmas'], target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "score = 'f1_macro'\n",
    "print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "print()\n",
    "np.errstate(divide='ignore')\n",
    "clf = GridSearchCV(text_clf, tuned_parameters, cv=10, scoring=score)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "for mean, std, params in zip(clf.cv_results_['mean_test_score'], \n",
    "                             clf.cv_results_['std_test_score'], \n",
    "                             clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "print(classification_report(y_val, clf.predict(X_val), digits=4))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.7227758007117437\n",
      "Accuracy for C=0.05: 0.7224199288256228\n",
      "Accuracy for C=0.25: 0.7128113879003559\n",
      "Accuracy for C=0.45: 0.702491103202847\n",
      "Accuracy for C=0.5: 0.700355871886121\n",
      "Accuracy for C=0.55: 0.698220640569395\n",
      "Accuracy for C=1: 0.6836298932384341\n",
      "Final Accuracy: 0.7227758007117437\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1    0.70482   0.72973   0.71706       481\n",
      "           0    0.77668   0.67862   0.72435      1394\n",
      "           1    0.67093   0.78503   0.72351       935\n",
      "\n",
      "   micro avg    0.72278   0.72278   0.72278      2810\n",
      "   macro avg    0.71748   0.73113   0.72164      2810\n",
      "weighted avg    0.72919   0.72278   0.72282      2810\n",
      "\n",
      "Wall time: 18.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, min_df=6, norm='l2', ngram_range=(1, 2),encoding='cp1251', \n",
    "                                   stop_words=stopwords.words('russian'))\n",
    "\n",
    "tfidf_vectorizer.fit(train['lemmas'])\n",
    "X = tfidf_vectorizer.transform(train['lemmas'])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.66\n",
    ")\n",
    "\n",
    "for alpha in [0.01, 0.05, 0.25, 0.45, 0.5, 0.55, 1]:\n",
    "    \n",
    "    NB = OneVsRestClassifier(MultinomialNB(alpha = alpha, fit_prior=True, class_prior=None))\n",
    "    NB.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (alpha, accuracy_score(y_val, NB.predict(X_val))))\n",
    "    \n",
    "    \n",
    "final_NB_tfidf = OneVsRestClassifier(MultinomialNB(alpha=0.01, fit_prior=True, class_prior=None))\n",
    "final_NB_tfidf.fit(X_train, y_train)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(y_val, final_NB_tfidf.predict(X_val)))\n",
    "print (classification_report(y_val,final_NB_tfidf.predict(X_val), digits = 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
